# -*- coding: utf-8 -*-
"""corpus_analysis_indi_bias.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pNGqRdljhqyr73uYhqdemXYGj15QyVfQ

### Benchmark Construction
"""

#!/usr/bin/env python3
"""
Script pour concat√©ner les fichiers CIRBE CSV avec une colonne de cat√©gorie
"""

import pandas as pd
import os

def concatenate_cirbe_files():
    """
    Concat√®ne tous les fichiers cirbe_cX_en_csv.txt en ajoutant une colonne 'category'
    """

    # Liste des fichiers √† traiter
    file_names = [
        'cirbe_c1_en_csv.txt',
        'cirbe_c2_en_csv.txt',
        'cirbe_c3_en_csv.txt',
        'cirbe_c4_en_csv.txt',
        'cirbe_c5_en_csv.txt',
        'cirbe_c6_en_csv.txt',
        'cirbe_c7_en_csv.txt',
        'cirbe_c8_en_csv.txt',
        'cirbe_c9_en_csv.txt',
        'cirbe_c10_en_csv.txt'
    ]

    # Liste pour stocker tous les DataFrames
    all_dfs = []

    # Traiter chaque fichier
    for file_name in file_names:
        print(f"Traitement de {file_name}...")

        # Extraire la cat√©gorie du nom de fichier (ex: 'c1' de 'cirbe_c1_en_csv.txt')
        category = file_name.split('_')[1].split('_')[0]  # Extrait 'c1', 'c2', etc.

        try:
            # Lire le fichier CSV
            df = pd.read_csv(file_name)

            # Ajouter la colonne category au d√©but
            df.insert(0, 'category', category)

            # Ajouter √† la liste
            all_dfs.append(df)

            print(f"  - {len(df)} lignes ajout√©es avec la cat√©gorie '{category}'")

        except FileNotFoundError:
            print(f"  - ERREUR: Fichier {file_name} non trouv√©!")
        except Exception as e:
            print(f"  - ERREUR lors du traitement: {e}")

    # Concat√©ner tous les DataFrames
    if all_dfs:
        final_df = pd.concat(all_dfs, ignore_index=True)

        # Sauvegarder le fichier final
        output_file = 'cirbe_all_categories_concatenated.csv'
        final_df.to_csv(output_file, index=False)

        print(f"\n‚úÖ Succ√®s! Fichier cr√©√©: {output_file}")
        print(f"üìä Statistiques:")
        print(f"  - Total de lignes: {len(final_df)}")
        print(f"  - Colonnes: {list(final_df.columns)}")
        print(f"\nüìà R√©partition par cat√©gorie:")
        print(final_df['category'].value_counts().sort_index())

        # Afficher un √©chantillon
        print(f"\nüîç √âchantillon des 5 premi√®res lignes:")
        print(final_df.head())

    else:
        print("\n‚ùå Aucun fichier n'a pu √™tre trait√©!")

if __name__ == "__main__":
    concatenate_cirbe_files()

#!/usr/bin/env python3
"""
Script pour cr√©er un fichier CSV avec tokens [MASK] uniformis√©s pour BERT
"""

import pandas as pd
import re

def create_bert_compatible_csv(input_file='cirbe_all_categories_concatenated.csv',
                              output_file='cirbe_bert_ready.csv'):
    """
    Lit le fichier CSV concat√©n√© et remplace tous les <mask> par [MASK] pour BERT

    Args:
        input_file: Nom du fichier d'entr√©e
        output_file: Nom du fichier de sortie compatible BERT
    """

    print(f"üìñ Lecture du fichier: {input_file}")

    try:
        # Lire le fichier CSV
        df = pd.read_csv(input_file)

        print(f"‚úÖ Fichier lu avec succ√®s: {len(df)} lignes")

        # Compter les occurrences avant correction
        mask_count = df['prompt'].str.contains('<mask>', regex=False).sum()
        bracket_mask_count = df['prompt'].str.contains('[MASK]', regex=False).sum()

        print(f"\nüìä Avant correction:")
        print(f"  - <mask>: {mask_count} occurrences")
        print(f"  - [MASK]: {bracket_mask_count} occurrences")

        # Remplacer tous les <mask> par [MASK]
        df['prompt'] = df['prompt'].str.replace('<mask>', '[MASK]', regex=False)

        # V√©rifier apr√®s correction
        mask_count_after = df['prompt'].str.contains('<mask>', regex=False).sum()
        bracket_mask_count_after = df['prompt'].str.contains('[MASK]', regex=False).sum()

        print(f"\n‚ú® Apr√®s correction:")
        print(f"  - <mask>: {mask_count_after} occurrences")
        print(f"  - [MASK]: {bracket_mask_count_after} occurrences")

        # Sauvegarder le fichier corrig√©
        df.to_csv(output_file, index=False)

        print(f"\n‚úÖ Fichier BERT-compatible cr√©√©: {output_file}")

        # Afficher des statistiques
        print(f"\nüìà Statistiques du fichier:")
        print(f"  - Total de lignes: {len(df)}")
        print(f"  - Cat√©gories: {sorted(df['category'].unique())}")
        print(f"  - Lignes par cat√©gorie:")
        for cat in sorted(df['category'].unique()):
            count = len(df[df['category'] == cat])
            print(f"    {cat}: {count} lignes")

        # Afficher un √©chantillon
        print(f"\nüîç √âchantillon (3 premi√®res lignes):")
        for idx, row in df.head(3).iterrows():
            print(f"\nLigne {idx+1}:")
            print(f"  Cat√©gorie: {row['category']}")
            print(f"  Prompt: {row['prompt'][:100]}...")
            print(f"  R√©ponse favorable: {row['favorable_answer']}")
            print(f"  R√©ponse d√©favorable: {row['unfavorable_answer']}")

        # Validation finale
        print(f"\n‚úÖ Validation finale:")
        if mask_count_after == 0 and bracket_mask_count_after == len(df):
            print("  ‚úì Tous les tokens de masque sont maintenant [MASK]")
            print("  ‚úì Fichier pr√™t pour l'utilisation avec BERT!")
        else:
            print("  ‚ö†Ô∏è Attention: v√©rifiez le fichier manuellement")

        return df

    except FileNotFoundError:
        print(f"‚ùå Erreur: Fichier '{input_file}' non trouv√©!")
        print("Assurez-vous d'avoir d'abord ex√©cut√© le script de concat√©nation.")
    except Exception as e:
        print(f"‚ùå Erreur lors du traitement: {e}")

    return None

if __name__ == "__main__":
    # Cr√©er le fichier compatible BERT
    df = create_bert_compatible_csv()

    if df is not None:
        print("\nüéØ Pr√™t pour l'analyse avec BERT!")
        print("Utilisez le fichier 'cirbe_bert_ready.csv' pour votre mod√®le.")